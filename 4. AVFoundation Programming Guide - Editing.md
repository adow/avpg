# 4. AVFoundation Programming Guide - Editing

原文地址：[https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/03\_Editing.html#//apple\_ref/doc/uid/TP40010188-CH8-SW1](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/03_Editing.html#//apple_ref/doc/uid/TP40010188-CH8-SW1)

大纲:

- 创建合成器 Creating a Composition
	- 创建合成轨道时的参数 Options for Initializing a Composition Track
- 往合成器中添加视音频数据 Adding Audiovisual Data to a Composition
	- 获取兼容的合成器轨道 Retrieving Compatible Composition Tracks
	- 实现音量变化 Generating a Volume Ramp
- 自定义的视频处理 Performing Custom Video Processing
	- 修改合成器的背景颜色 Changing the Composition’s Background Color
	- 修改透明度 Applying Opacity Ramps
	- 在合成器中使用动画特效 Incorporating Core Animation Effects
- 整合在一起：合并多个 `Asset` 并输出到照片库
	- 创建合成器 Creating the Composition
	- 添加 assets Adding the Assets
	- 检查视频方向 Checking the Video Orientations
	- 应用视频合成器的图层指令 Applying the Video Composition Layer Instructions
	- 设置渲染尺寸和帧时长 Setting the Render Size and Frame Duration
	- 从合成器输出到相机的照片胶卷库中 Exporting the Composition and Saving it to the Camera Roll

## 编辑 Editing

The AVFoundation framework provides a feature-rich set of classes to facilitate the editing of audio visual assets. At the heart of AVFoundation’s editing API are compositions. A composition is simply a collection of tracks from one or more different media assets. The [AVMutableComposition ](https://developer.apple.com/documentation/avfoundation/avmutablecomposition)class provides an interface for inserting and removing tracks, as well as managing their temporal orderings. Figure 3-1 shows how a new composition is pieced together from a combination of existing assets to form a new asset. If all you want to do is merge multiple assets together sequentially into a single file, that is as much detail as you need. If you want to perform any custom audio or video processing on the tracks in your composition, you need to incorporate an audio mix or a video composition, respectively.

`AVFoundation` 框架中提供了丰富的类来方便的进行音视频编辑。这一组 API 的核心是合成器（`compositions`）。合成器就是把来自不同的媒体 asset 中的轨道组合成一组。[AVMutableComposition ](https://developer.apple.com/documentation/avfoundation/avmutablecomposition) 类提供了插入和删除轨道的接口，除此之外还可以管理他们的时间顺序。图 3-1 展示了 如何从几个现有的 asset 合成来组合成一个新的合成并输出一个新的 asset。这展示了如何将多个 asset 按照顺序 合并成一个文件。如果你还想对音频和视频轨道做自定义处理，你还需要单独处理声音的合成和视频的拼接。

![](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/avmutablecomposition_2x.png)

Using the [AVMutableAudioMix](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix) class, you can perform custom audio processing on the audio tracks in your composition, as shown in Figure 3-2. Currently, you can specify a maximum volume or set a volume ramp for an audio track.

通过 [AVMutableAudioMix](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix),你可以在合成的过程中对音频进行单独的处理。3-2 展示了你可以设置音频轨道的最大音量或者修改调速 （`volume ramp`）。

![](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/avmutableaudiomix_2x.png)

You can use the [AVMutableVideoComposition ](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition)class to work directly with the video tracks in your composition for the purposes of editing, shown in Figure 3-3. With a single video composition, you can specify the desired render size and scale, as well as the frame duration, for the output video. Through a video composition’s instructions (represented by the [AVMutableVideoCompositionInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction) class), you can modify the background color of your video and apply layer instructions. These layer instructions (represented by the [AVMutableVideoCompositionLayerInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction) class) can be used to apply transforms, transform ramps, opacity and opacity ramps to the video tracks within your composition. The video composition class also gives you the ability to introduce effects from the Core Animation framework into your video using the [animationTool](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390395-animationtool) property.

图 3-3 展示了你可以通过使用 [AVMutableVideoComposition ](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition) 在合成中直接编辑视频轨道。对于单个视频合成，你可以在输出视频时指定尺寸，缩放和帧的时间。通过合成器的指令（通过 [AVMutableVideoCompositionInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction) 类表示），你可以修改视频的背景颜色和使用图层的指令器。这些图层指令（通过 [AVMutableVideoCompositionLayerInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction) 类表示）可以用来在合成器中对视频轨道实现变形，transform ramps,透明度，透明，opacity ramps. 通过使用 [animationTool](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390395-animationtool) 属性,视频的合成器还可以让你在视频中使用 `Core Animation` 框架的特效。

![](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/avmutablevideocomposition_2x.png)

To combine your composition with an audio mix and a video composition, you use an [AVAssetExportSession](https://developer.apple.com/documentation/avfoundation/avassetexportsession) object, as shown in Figure 3-4. You initialize the export session with your composition and then simply assign your audio mix and video composition to the [audioMix](https://developer.apple.com/documentation/avfoundation/avassetexportsession/1388155-audiomix) and [videoComposition](https://developer.apple.com/documentation/avfoundation/avassetexportsession/1389477-videocomposition) properties respectively.

要把音频合成和视频合成再组合成一个，你需要使用 [AVAssetExportSession](https://developer.apple.com/documentation/avfoundation/avassetexportsession) 对象。在 3-4 中，你通过一个合成器来创建输出对象 （`export session`），然后只需要将音轨的合成指定到 [audioMix](https://developer.apple.com/documentation/avfoundation/avassetexportsession/1388155-audiomix) 属性，将视频的合成指定到 [videoComposition](https://developer.apple.com/documentation/avfoundation/avassetexportsession/1389477-videocomposition) 属性就可以了。

![](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/puttingitalltogether_2x.png)  

### 创建合成器 Creating a Composition

To create your own composition, you use the [AVMutableComposition](https://developer.apple.com/documentation/avfoundation/avmutablecomposition) class. To add media data to your composition, you must add one or more composition tracks, represented by the [AVMutableCompositionTrack](https://developer.apple.com/documentation/avfoundation/avmutablecompositiontrack) class. The simplest case is creating a mutable composition with one video track and one audio track:

你通过使用 [AVMutableComposition](https://developer.apple.com/documentation/avfoundation/avmutablecomposition) 来创建一个合成器。你需要往其中添加多个合成轨道 [AVMutableCompositionTrack](https://developer.apple.com/documentation/avfoundation/avmutablecompositiontrack) 。最简单的情况是，你在一个可修改合成器 （`mutable composition`） 中添加一个视频轨道和一个音频轨道。

	AVMutableComposition *mutableComposition = [AVMutableComposition composition];
	// Create the video composition track.
	AVMutableCompositionTrack *mutableCompositionVideoTrack = [mutableComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid];
	// Create the audio composition track.
	AVMutableCompositionTrack *mutableCompositionAudioTrack = [mutableComposition addMutableTrackWithMediaType:AVMediaTypeAudio preferredTrackID:kCMPersistentTrackID_Invalid];
	

#### 创建合成轨道时的参数 Options for Initializing a Composition Track

When adding new tracks to a composition, you must provide both a media type and a track ID. Although audio and video are the most commonly used media types, you can specify other media types as well, such as [AVMediaTypeSubtitle](https://developer.apple.com/documentation/avfoundation/avmediatype/1390709-subtitle) or [AVMediaTypeText](https://developer.apple.com/documentation/avfoundation/avmediatypetext).

Every track associated with some audiovisual data has a unique identifier referred to as a track ID. If you specify [`kCMPersistentTrackID_Invalid`](https://developer.apple.com/documentation/coremedia/1388099-invalid_track_id_specifier/kcmpersistenttrackid_invalid) as the preferred track ID, a unique identifier is automatically generated for you and associated with the track.

当你创建合成器的轨道的时候，你必须指定媒体类型 （`media type`） 和 轨道 ID （`track ID`）。虽然大多数时候的媒体类型都是视频和音频，但是你其实还可以指定其他的媒体类型，比如字幕 [AVMediaTypeSubtitle](https://developer.apple.com/documentation/avfoundation/avmediatype/1390709-subtitle) 和 文本 [AVMediaTypeText](https://developer.apple.com/documentation/avfoundation/avmediatypetext)。 

每个承载视音频数据的轨道都有一个唯一的 `track ID`。你也可以指定一个预设的 [`kCMPersistentTrackID_Invalid`](https://developer.apple.com/documentation/coremedia/1388099-invalid_track_id_specifier/kcmpersistenttrackid_invalid)，这时框架会自动为你创建一个唯一的轨道 ID。

### 往合成器中添加视音频数据 Adding Audiovisual Data to a Composition

Once you have a composition with one or more tracks, you can begin adding your media data to the appropriate tracks. To add media data to a composition track, you need access to the [AVAsset](https://developer.apple.com/documentation/avfoundation/avasset) object where the media data is located. You can use the mutable composition track interface to place multiple tracks with the same underlying media type together on the same track. The following example illustrates how to add two different video asset tracks in sequence to the same composition track:

当你的合成器中有一个或者多个轨道时，你就可以开始往合适的轨道中添加媒体数据。这时你需要访问 [AVAsset](https://developer.apple.com/documentation/avfoundation/avasset) 对象，他承载着媒体数据。你可以使用可变合成器轨道将多个拥有相同底层媒体类型的轨道放在同一个轨道上。下面的代码示例了如何将两个不同的视频轨道依次放置在同一个合成轨道上。

	// You can retrieve AVAssets from a number of places, like the camera roll for example.
	AVAsset *videoAsset = <#AVAsset with at least one video track#>;
	AVAsset *anotherVideoAsset = <#another AVAsset with at least one video track#>;
	// Get the first video track from each asset.
	AVAssetTrack *videoAssetTrack = [[videoAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
	AVAssetTrack *anotherVideoAssetTrack = [[anotherVideoAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
	// Add them both to the composition.
	[mutableCompositionVideoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero,videoAssetTrack.timeRange.duration) ofTrack:videoAssetTrack atTime:kCMTimeZero error:nil];
	[mutableCompositionVideoTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero,anotherVideoAssetTrack.timeRange.duration) ofTrack:anotherVideoAssetTrack atTime:videoAssetTrack.timeRange.duration error:nil];
	

#### 获取兼容的合成器轨道 Retrieving Compatible Composition Tracks

Where possible, you should have only one composition track for each media type. This unification of compatible asset tracks leads to a minimal amount of resource usage. When presenting media data serially, you should place any media data of the same type on the same composition track. You can query a mutable composition to find out if there are any composition tracks compatible with your desired asset track:

尽可能的在一个合成器轨道中放置相同的媒体类型数据。这种统一兼容的的轨道 （`asset track`） 可以最大幅度的降低资源消耗。当你依次播放媒体数据时，你应该把类型相同的媒体数据放在同一个合成器轨道中。你可以通过查询可修改合成器 （`mutable composition`） 来确定是否有哪些合成器轨道 （`composition track`） 和你的 asset 轨道  （`asset track`） 兼容。

	AVMutableCompositionTrack *compatibleCompositionTrack = [mutableComposition mutableTrackCompatibleWithTrack:<#the AVAssetTrack you want to insert#>];
	if (compatibleCompositionTrack) {
	    // Implementation continues.
	}

Note: Placing multiple video segments on the same composition track can potentially lead to dropping frames in the playback at the transitions between video segments, especially on embedded devices. Choosing the number of composition tracks for your video segments depends entirely on the design of your app and its intended platform.


提示：把多个视频片段放在同一个合成器轨道中可能会在视频转场的时候也引起丢帧，这在嵌入式设备上更加明显。为你的视频片段使用多少合成轨道取决于你的 App 的设计和目标平台。

#### 实现音量变化 Generating a Volume Ramp

A single `AVMutableAudioMix` object can perform custom audio processing on all of the audio tracks in your composition individually. You create an audio mix using the [audioMix](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix/1560973-audiomix) class method, and you use instances of the [AVMutableAudioMixInputParameters](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters) class to associate the audio mix with specific tracks within your composition. An audio mix can be used to vary the volume of an audio track. The following example displays how to set a volume ramp on a specific audio track to slowly fade the audio out over the duration of the composition:

通过使用 `AVMutableAudioMix` 对象你可以对合成器中的每个音频轨道做自定义的处理。你可以使用 [audioMix](https://developer.apple.com/documentation/avfoundation/avmutableaudiomix/1560973-audiomix) 中的方法，并将一个 [AVMutableAudioMixInputParameters](https://developer.apple.com/documentation/avfoundation/avmutableaudiomixinputparameters) 对象和特定的合成器轨关联。`Audio Mix` 可以用来改变音频轨道中的音量。下面代码示例了如何根据时间的流逝来慢慢的减弱音量

	AVMutableAudioMix *mutableAudioMix = [AVMutableAudioMix audioMix];
	// Create the audio mix input parameters object.
	AVMutableAudioMixInputParameters *mixParameters = [AVMutableAudioMixInputParameters audioMixInputParametersWithTrack:mutableCompositionAudioTrack];
	// Set the volume ramp to slowly fade the audio out over the duration of the composition.
	[mixParameters setVolumeRampFromStartVolume:1.f toEndVolume:0.f timeRange:CMTimeRangeMake(kCMTimeZero, mutableComposition.duration)];
	// Attach the input parameters to the audio mix.
	mutableAudioMix.inputParameters = @[mixParameters];
	

### 自定义的视频处理 Performing Custom Video Processing

As with an audio mix, you only need one `AVMutableVideoComposition` object to perform all of your custom video processing on your composition’s video tracks. Using a video composition, you can directly set the appropriate render size, scale, and frame rate for your composition’s video tracks. For a detailed example of setting appropriate values for these properties, see [Setting the Render Size and Frame Duration](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/03_Editing.html#//apple_ref/doc/uid/TP40010188-CH8-SW18).

和 `audio mix` 一样，你需要用 `AVMutableVideoComposition` 对象来对合成器中的视频轨道进行处理。通过使用视频合成器 （`video composition`）, 你可以实现修改尺寸，缩放以及修改视频轨道中的帧率。关于如何设置这些属性的示例代码，可以参考 [Setting the Render Size and Frame Duration](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/03_Editing.html#//apple_ref/doc/uid/TP40010188-CH8-SW18)

#### 修改合成器的背景颜色 Changing the Composition’s Background Color

All video compositions must also have an array of [AVVideoCompositionInstruction](https://developer.apple.com/documentation/avfoundation/avvideocompositioninstruction) objects containing at least one video composition instruction. You use the [AVMutableVideoCompositionInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction) class to create your own video composition instructions. Using video composition instructions, you can modify the composition’s background color, specify whether post processing is needed or apply layer instructions.

The following example illustrates how to create a video composition instruction that changes the background color to red for the entire composition.

所有的视频合成器都有一组视频合成指令 `AVVideoCompositionInstruction`，其中至少包含一些配置。你可以用 `AVMutableVideoCompositionInstruction` 来创建直接的视频合成器指令。通过视频合成器的指令，你可以修改合成器的背景色，也可以按需处理，以及是否将他应用于图层指令 （`layer instructions`）。

下面的代码示例了如何创建一个视频合成器指令，并将合成器背景色修改为红色

	AVMutableVideoCompositionInstruction *mutableVideoCompositionInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
	mutableVideoCompositionInstruction.timeRange = CMTimeRangeMake(kCMTimeZero, mutableComposition.duration);
	mutableVideoCompositionInstruction.backgroundColor = [[UIColor redColor] CGColor];
	

#### 修改透明度 Applying Opacity Ramps

Video composition instructions can also be used to apply video composition layer instructions. An [AVMutableVideoCompositionLayerInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction) object can apply transforms, transform ramps, opacity and opacity ramps to a certain video track within a composition. The order of the layer instructions in a video composition instruction’s [layerInstructions](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction/1388912-layerinstructions) array determines how video frames from source tracks should be layered and composed for the duration of that composition instruction. The following code fragment shows how to set an opacity ramp to slowly fade out the first video in a composition before transitioning to the second video:

视频合成的指令 （`video composition instructions`） 还可以用来应用于视频合成器的图层的指令 （`video composition layer instructions`）。一个可变的视频合成器图层指令对象 [AVMutableVideoCompositionLayerInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction) 可用来在视频合成的过程中对特定的视频轨道进行变形，透明的的修改。视频合成器指令 （`video composition instructions`） 的[layerInstructions](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositioninstruction/1388912-layerinstructions) 属性是一组图层指示器 （`layer instructions`）数组，他决定了例如视频轨道中的帧在合成指令的过程中随着时间的变化中是如何被图层显示和合成的。下面的代码示例了第一个视频如何通过修改透明度变化过渡到第二个视频的

	AVAsset *firstVideoAssetTrack = <#AVAssetTrack representing the first video segment played in the composition#>;
	AVAsset *secondVideoAssetTrack = <#AVAssetTrack representing the second video segment played in the composition#>;
	// Create the first video composition instruction.
	AVMutableVideoCompositionInstruction *firstVideoCompositionInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
	// Set its time range to span the duration of the first video track.
	firstVideoCompositionInstruction.timeRange = CMTimeRangeMake(kCMTimeZero, firstVideoAssetTrack.timeRange.duration);
	// Create the layer instruction and associate it with the composition video track.
	AVMutableVideoCompositionLayerInstruction *firstVideoLayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:mutableCompositionVideoTrack];
	// Create the opacity ramp to fade out the first video track over its entire duration.
	[firstVideoLayerInstruction setOpacityRampFromStartOpacity:1.f toEndOpacity:0.f timeRange:CMTimeRangeMake(kCMTimeZero, firstVideoAssetTrack.timeRange.duration)];
	// Create the second video composition instruction so that the second video track isn't transparent.
	AVMutableVideoCompositionInstruction *secondVideoCompositionInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
	// Set its time range to span the duration of the second video track.
	secondVideoCompositionInstruction.timeRange = CMTimeRangeMake(firstVideoAssetTrack.timeRange.duration, CMTimeAdd(firstVideoAssetTrack.timeRange.duration, secondVideoAssetTrack.timeRange.duration));
	// Create the second layer instruction and associate it with the composition video track.
	AVMutableVideoCompositionLayerInstruction *secondVideoLayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:mutableCompositionVideoTrack];
	// Attach the first layer instruction to the first video composition instruction.
	firstVideoCompositionInstruction.layerInstructions = @[firstVideoLayerInstruction];
	// Attach the second layer instruction to the second video composition instruction.
	secondVideoCompositionInstruction.layerInstructions = @[secondVideoLayerInstruction];
	// Attach both of the video composition instructions to the video composition.
	AVMutableVideoComposition *mutableVideoComposition = [AVMutableVideoComposition videoComposition];
	mutableVideoComposition.instructions = @[firstVideoCompositionInstruction, secondVideoCompositionInstruction];
	

#### 在合成器中使用动画特效 Incorporating Core Animation Effects

A video composition can add the power of Core Animation to your composition through the [animationTool](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390395-animationtool) property. Through this animation tool, you can accomplish tasks such as watermarking video and adding titles or animating overlays. Core Animation can be used in two different ways with video compositions: You can add a Core Animation layer as its own individual composition track, or you can render Core Animation effects (using a Core Animation layer) into the video frames in your composition directly. The following code displays the latter option by adding a watermark to the center of the video:

在视频的合成器中可以通过 [animationTool](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390395-animationtool) 属性来添加 `Core Animation` 的特效能力。通过这个方法，你可以实现水印，添加标题和动画图层等。 在合成中有两种方法来使用 `Core Animation`：你可以通过添加一个动画图层 （`Core Animation Layer`） 作为一个单独的合成轨道，你可以可以在合成的过程中使用 动画图层 （`Core Animation Layer`）直接渲染每一帧。下面的代码展示了使用第二种方法在视频的中间添加一个水印

	CALayer *watermarkLayer = <#CALayer representing your desired watermark image#>;
	CALayer *parentLayer = [CALayer layer];
	CALayer *videoLayer = [CALayer layer];
	parentLayer.frame = CGRectMake(0, 0, mutableVideoComposition.renderSize.width, mutableVideoComposition.renderSize.height);
	videoLayer.frame = CGRectMake(0, 0, mutableVideoComposition.renderSize.width, mutableVideoComposition.renderSize.height);
	[parentLayer addSublayer:videoLayer];
	watermarkLayer.position = CGPointMake(mutableVideoComposition.renderSize.width/2, mutableVideoComposition.renderSize.height/4);
	[parentLayer addSublayer:watermarkLayer];
	mutableVideoComposition.animationTool = [AVVideoCompositionCoreAnimationTool videoCompositionCoreAnimationToolWithPostProcessingAsVideoLayer:videoLayer inLayer:parentLayer];
	

### 整合在一起：合并多个 `Asset` 并输出到照片库

This brief code example illustrates how you can combine two video asset tracks and an audio asset track to create a single video file. It shows how to:

- Create an [AVMutableComposition](https://developer.apple.com/documentation/avfoundation/avmutablecomposition) object and add multiple [AVMutableCompositionTrack](https://developer.apple.com/documentation/avfoundation/avmutablecompositiontrack) objects
- Add time ranges of [AVAssetTrack](https://developer.apple.com/documentation/avfoundation/avassettrack) objects to compatible composition tracks
- Check the [preferredTransform](https://developer.apple.com/documentation/avfoundation/avassettrack/1389837-preferredtransform) property of a video asset track to determine the video’s orientation
- Use [AVMutableVideoCompositionLayerInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction) objects to apply transforms to the video tracks within a composition
- Set appropriate values for the [renderSize](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1386365-rendersize) and [frameDuration](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390059-frameduration) properties of a video composition
- Use a composition in conjunction with a video composition when exporting to a video file
- Save a video file to the Camera Roll

下面这个简短的代码示例了如何将两个视频轨道和一个音频轨道合并创建出一个视频文件，他包括：

- 创建一个可修改的合成器 [AVMutableComposition](https://developer.apple.com/documentation/avfoundation/avmutablecomposition) 和多个可修改的合成器轨道 [AVMutableCompositionTrack](https://developer.apple.com/documentation/avfoundation/avmutablecompositiontrack)；
- 在轨道 [AVAssetTrack](https://developer.apple.com/documentation/avfoundation/avassettrack) 中选择了一段时间给合适的合成器轨道 （`compatible composition tracks`）。
- 通过视频轨道 （`video asset track`） 中的 [preferredTransform](https://developer.apple.com/documentation/avfoundation/avassettrack/1389837-preferredtransform) 属性来确定视频的方向；
- 在视频合成器中，通过使用视频合成器的图层指令 [AVMutableVideoCompositionLayerInstruction](https://developer.apple.com/documentation/avfoundation/avmutablevideocompositionlayerinstruction) 对视频轨道进行变形；
- 在视频合成中设置合适的 [renderSize](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1386365-rendersize) 和 [frameDuration](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390059-frameduration) 属性值；
- 在输出视频文件的时候，通过一个合成器来连接视频合成器；
- 输出文件保存到相机的照片胶卷库；

Note: To focus on the most relevant code, this example omits several aspects of a complete app, such as memory management and error handling. To use AVFoundation, you are expected to have enough experience with Cocoa to infer the missing pieces.


提示：以下代码只是为了展示如何使用相关的代码，并没有包括作为一个完整的 App 的其他需要的部分，比如内存管理，错误处理等；在使用 `AVFoundation` 框架的时候，你需要对于其他这里未提及的知识有足够的经验。

#### 创建合成器 Creating the Composition

To piece together tracks from separate assets, you use an `AVMutableComposition` object. Create the composition and add one audio and one video track.

通过一个可变的合成器 `AVMutableComposition` 来将不同 asset 的轨道合并起来，然后往其中添加一个视频轨道和一个音频轨道。

	AVMutableComposition *mutableComposition = [AVMutableComposition composition];
	AVMutableCompositionTrack *videoCompositionTrack = [mutableComposition addMutableTrackWithMediaType:AVMediaTypeVideo preferredTrackID:kCMPersistentTrackID_Invalid];
	AVMutableCompositionTrack *audioCompositionTrack = [mutableComposition addMutableTrackWithMediaType:AVMediaTypeAudio preferredTrackID:kCMPersistentTrackID_Invalid];
	

#### 添加 assets Adding the Assets

An empty composition does you no good. Add the two video asset tracks and the audio asset track to the composition.

一个空的合成器一点用都没有，你还得将两个视频轨道 （`video asset tracks`） 和一个音频轨道 （`audio asset track`） 添加到合成器中。

	AVAssetTrack *firstVideoAssetTrack = [[firstVideoAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
	AVAssetTrack *secondVideoAssetTrack = [[secondVideoAsset tracksWithMediaType:AVMediaTypeVideo] objectAtIndex:0];
	[videoCompositionTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, firstVideoAssetTrack.timeRange.duration) ofTrack:firstVideoAssetTrack atTime:kCMTimeZero error:nil];
	[videoCompositionTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, secondVideoAssetTrack.timeRange.duration) ofTrack:secondVideoAssetTrack atTime:firstVideoAssetTrack.timeRange.duration error:nil];
	[audioCompositionTrack insertTimeRange:CMTimeRangeMake(kCMTimeZero, CMTimeAdd(firstVideoAssetTrack.timeRange.duration, secondVideoAssetTrack.timeRange.duration)) ofTrack:[[audioAsset tracksWithMediaType:AVMediaTypeAudio] objectAtIndex:0] atTime:kCMTimeZero error:nil];

Note: This assumes that you have two assets that contain at least one video track each and a third asset that contains at least one audio track. The videos can be retrieved from the Camera Roll, and the audio track can be retrieved from the music library or the videos themselves.

提示：这里假定两个视频 asset 中至少都还有一个视频轨道，一个音频 asset 中至少有一个音频轨道。你可以从相机胶卷库中获取视频文件，从音乐库或者视频文件中来获取音频轨道。

#### 检查视频方向 Checking the Video Orientations

Once you add your video and audio tracks to the composition, you need to ensure that the orientations of both video tracks are correct. By default, all video tracks are assumed to be in landscape mode. If your video track was taken in portrait mode, the video will not be oriented properly when it is exported. Likewise, if you try to combine a video shot in portrait mode with a video shot in landscape mode, the export session will fail to complete.

在添加完音视频轨道 （`vidoe and audio tracks`） 后，你需要检查两个视频轨道的方法是不是都正确。视频轨道的默认方法都是横屏  （`landscape`） 的。如果你的视频轨道在拍摄的时候是竖屏 （`portait`） 的，那他在输出的时候是不会被自动转向的。同样，如果你尝试将一个竖屏的视频和一个横屏的竖屏进行合并，输出的时候也会失败。

	BOOL isFirstVideoPortrait = NO;
	CGAffineTransform firstTransform = firstVideoAssetTrack.preferredTransform;
	// Check the first video track's preferred transform to determine if it was recorded in portrait mode.
	if (firstTransform.a == 0 && firstTransform.d == 0 && (firstTransform.b == 1.0 || firstTransform.b == -1.0) && (firstTransform.c == 1.0 || firstTransform.c == -1.0)) {
	    isFirstVideoPortrait = YES;
	}
	BOOL isSecondVideoPortrait = NO;
	CGAffineTransform secondTransform = secondVideoAssetTrack.preferredTransform;
	// Check the second video track's preferred transform to determine if it was recorded in portrait mode.
	if (secondTransform.a == 0 && secondTransform.d == 0 && (secondTransform.b == 1.0 || secondTransform.b == -1.0) && (secondTransform.c == 1.0 || secondTransform.c == -1.0)) {
	    isSecondVideoPortrait = YES;
	}
	if ((isFirstVideoAssetPortrait && !isSecondVideoAssetPortrait) || (!isFirstVideoAssetPortrait && isSecondVideoAssetPortrait)) {
	    UIAlertView *incompatibleVideoOrientationAlert = [[UIAlertView alloc] initWithTitle:@"Error!" message:@"Cannot combine a video shot in portrait mode with a video shot in landscape mode." delegate:self cancelButtonTitle:@"Dismiss" otherButtonTitles:nil];
	    [incompatibleVideoOrientationAlert show];
	    return;
	}
	

#### 应用视频合成器的图层指令 Applying the Video Composition Layer Instructions

Once you know the video segments have compatible orientations, you can apply the necessary layer instructions to each one and add these layer instructions to the video composition.

当你知道了每个视频片段有正确的方向后，你可以为每个需要的视频片段使用图层指令 ）`layer instructions`），然后将他们添加到视频合成器中。

	AVMutableVideoCompositionInstruction *firstVideoCompositionInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
	// Set the time range of the first instruction to span the duration of the first video track.
	firstVideoCompositionInstruction.timeRange = CMTimeRangeMake(kCMTimeZero, firstVideoAssetTrack.timeRange.duration);
	AVMutableVideoCompositionInstruction * secondVideoCompositionInstruction = [AVMutableVideoCompositionInstruction videoCompositionInstruction];
	// Set the time range of the second instruction to span the duration of the second video track.
	secondVideoCompositionInstruction.timeRange = CMTimeRangeMake(firstVideoAssetTrack.timeRange.duration, CMTimeAdd(firstVideoAssetTrack.timeRange.duration, secondVideoAssetTrack.timeRange.duration));
	AVMutableVideoCompositionLayerInstruction *firstVideoLayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:videoCompositionTrack];
	// Set the transform of the first layer instruction to the preferred transform of the first video track.
	[firstVideoLayerInstruction setTransform:firstTransform atTime:kCMTimeZero];
	AVMutableVideoCompositionLayerInstruction *secondVideoLayerInstruction = [AVMutableVideoCompositionLayerInstruction videoCompositionLayerInstructionWithAssetTrack:videoCompositionTrack];
	// Set the transform of the second layer instruction to the preferred transform of the second video track.
	[secondVideoLayerInstruction setTransform:secondTransform atTime:firstVideoAssetTrack.timeRange.duration];
	firstVideoCompositionInstruction.layerInstructions = @[firstVideoLayerInstruction];
	secondVideoCompositionInstruction.layerInstructions = @[secondVideoLayerInstruction];
	AVMutableVideoComposition *mutableVideoComposition = [AVMutableVideoComposition videoComposition];
	mutableVideoComposition.instructions = @[firstVideoCompositionInstruction, secondVideoCompositionInstruction];

All [AVAssetTrack](https://developer.apple.com/documentation/avfoundation/avassettrack) objects have a [preferredTransform](https://developer.apple.com/documentation/avfoundation/avassettrack/1389837-preferredtransform) property that contains the orientation information for that asset track. This transform is applied whenever the asset track is displayed onscreen. In the previous code, the layer instruction’s transform is set to the asset track’s transform so that the video in the new composition displays properly once you adjust its render size.

每个轨道 [AVAssetTrack](https://developer.apple.com/documentation/avfoundation/avassettrack) 对象都有一个 [preferredTransform](https://developer.apple.com/documentation/avfoundation/avassettrack/1389837-preferredtransform) 属性用来包含方向信息。在 轨道 （`asset track`） 被显示在屏幕上的时候，这个属性就会被使用。在之前的代码中，由于图层指令 （`layer instruction`） 的变化 （`transform`） 设置为和 asset 视频轨道中输出的变化 （`transform`） 一样了，所以新的合成器中只需要调整显示尺寸后就可以正确的渲染出视频。 

#### 设置渲染尺寸和帧时长 Setting the Render Size and Frame Duration

To complete the video orientation fix, you must adjust the [renderSize](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1386365-rendersize) property accordingly. You should also pick a suitable value for the [frameDuration](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390059-frameduration) property, such as 1/30th of a second (or 30 frames per second). By default, the [renderScale](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1615787-renderscale) property is set to 1.0, which is appropriate for this composition.

在修改视频方向的过程中，你还需要调整渲染尺寸 [renderSize](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1386365-rendersize)。你还需要指定一个合适的帧时长属性 [frameDuration](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1390059-frameduration)，比如 `1/30` 秒 (每秒30帧）。默认的情况下 [renderScale](https://developer.apple.com/documentation/avfoundation/avmutablevideocomposition/1615787-renderscale) 属性在合成器中总是被设置为 `1.0`。

	CGSize naturalSizeFirst, naturalSizeSecond;
	// If the first video asset was shot in portrait mode, then so was the second one if we made it here.
	if (isFirstVideoAssetPortrait) {
	// Invert the width and height for the video tracks to ensure that they display properly.
	    naturalSizeFirst = CGSizeMake(firstVideoAssetTrack.naturalSize.height, firstVideoAssetTrack.naturalSize.width);
	    naturalSizeSecond = CGSizeMake(secondVideoAssetTrack.naturalSize.height, secondVideoAssetTrack.naturalSize.width);
	}
	else {
	// If the videos weren't shot in portrait mode, we can just use their natural sizes.
	    naturalSizeFirst = firstVideoAssetTrack.naturalSize;
	    naturalSizeSecond = secondVideoAssetTrack.naturalSize;
	}
	float renderWidth, renderHeight;
	// Set the renderWidth and renderHeight to the max of the two videos widths and heights.
	if (naturalSizeFirst.width > naturalSizeSecond.width) {
	    renderWidth = naturalSizeFirst.width;
	}
	else {
	    renderWidth = naturalSizeSecond.width;
	}
	if (naturalSizeFirst.height > naturalSizeSecond.height) {
	    renderHeight = naturalSizeFirst.height;
	}
	else {
	    renderHeight = naturalSizeSecond.height;
	}
	mutableVideoComposition.renderSize = CGSizeMake(renderWidth, renderHeight);
	// Set the frame duration to an appropriate value (i.e. 30 frames per second for video).
	mutableVideoComposition.frameDuration = CMTimeMake(1,30);
	

#### 从合成器输出到相机的照片胶卷库中 Exporting the Composition and Saving it to the Camera Roll

The final step in this process involves exporting the entire composition into a single video file and saving that video to the camera roll. You use an [AVAssetExportSession](https://developer.apple.com/documentation/avfoundation/avassetexportsession) object to create the new video file and you pass to it your desired URL for the output file. You can then use the [ALAssetsLibrary](https://developer.apple.com/documentation/assetslibrary/alassetslibrary) class to save the resulting video file to the Camera Roll.

这一系列处理的最后一步是将整个合成器输出到一个视频文件并保存到相机胶卷库中。通过指定一个 URL 来为指定一个视频文件并以此来创建一个输出对象 [AVAssetExportSession](https://developer.apple.com/documentation/avfoundation/avassetexportsession)。然后通过使用 [ALAssetsLibrary](https://developer.apple.com/documentation/assetslibrary/alassetslibrary) 将输出的视频文件保存到相机胶卷中。

	// Create a static date formatter so we only have to initialize it once.
	static NSDateFormatter *kDateFormatter;
	if (!kDateFormatter) {
	    kDateFormatter = [[NSDateFormatter alloc] init];
	    kDateFormatter.dateStyle = NSDateFormatterMediumStyle;
	    kDateFormatter.timeStyle = NSDateFormatterShortStyle;
	}
	// Create the export session with the composition and set the preset to the highest quality.
	AVAssetExportSession *exporter = [[AVAssetExportSession alloc] initWithAsset:mutableComposition presetName:AVAssetExportPresetHighestQuality];
	// Set the desired output URL for the file created by the export process.
	exporter.outputURL = [[[[NSFileManager defaultManager] URLForDirectory:NSDocumentDirectory inDomain:NSUserDomainMask appropriateForURL:nil create:@YES error:nil] URLByAppendingPathComponent:[kDateFormatter stringFromDate:[NSDate date]]] URLByAppendingPathExtension:CFBridgingRelease(UTTypeCopyPreferredTagWithClass((CFStringRef)AVFileTypeQuickTimeMovie, kUTTagClassFilenameExtension))];
	// Set the output file type to be a QuickTime movie.
	exporter.outputFileType = AVFileTypeQuickTimeMovie;
	exporter.shouldOptimizeForNetworkUse = YES;
	exporter.videoComposition = mutableVideoComposition;
	// Asynchronously export the composition to a video file and save this file to the camera roll once export completes.
	[exporter exportAsynchronouslyWithCompletionHandler:^{
	    dispatch_async(dispatch_get_main_queue(), ^{
	        if (exporter.status == AVAssetExportSessionStatusCompleted) {
	            ALAssetsLibrary *assetsLibrary = [[ALAssetsLibrary alloc] init];
	            if ([assetsLibrary videoAtPathIsCompatibleWithSavedPhotosAlbum:exporter.outputURL]) {
	                [assetsLibrary writeVideoAtPathToSavedPhotosAlbum:exporter.outputURL completionBlock:NULL];
	            }
	        }
	    });
	}];

