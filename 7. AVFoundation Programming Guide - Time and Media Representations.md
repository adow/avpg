# 7. AVFoundation Programming Guide - Time and Media Representations

原文地址：[https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/06\_MediaRepresentations.html#//apple\_ref/doc/uid/TP40010188-CH2-SW1](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/06_MediaRepresentations.html#//apple_ref/doc/uid/TP40010188-CH2-SW1)

大纲:

- 库的描述 Representation of Assets
- 对于时间的表示 Representations of Time
	- 使用 CMTime 表示时间长度 CMTime Represents a Length Time
	- 使用 CMTime  Using CMTime
	- CMTime 的一些特殊值 Special Values of CMTime
	- 将 CMTime 转换为对象 Representing CMTime as an Object
	- 时期 Epochs
	- 用 CMTimeRange 表示时间范围 CMTimeRange Represents a Time Range
	- 使用时间范围 Working with Time Ranges
	- 时间范围的特殊值 Special Values of CMTimeRange
	- 将 CMTimeRange 转换为对象 Representing a CMTimeRange Structure as an Object
- 媒体的展现 Representations of Media
- 将 CMSampleBuffer 转换为图像对象 Converting CMSampleBuffer to a UIImage Object

## 时间和媒体的描述 Time and Media Representations

Time-based audiovisual data, such as a movie file or a video stream, is represented in the AV Foundation framework by `AVAsset`. Its structure dictates much of the framework works. Several low-level data structures that AV Foundation uses to represent time and media such as sample buffers come from the Core Media framework.

在 `AVFoundation` 框架中，基于时间的音视频数据，比如影片文件或者视频流，是通过库 （`AVAsset`） 来进行表示/描述 （`represented`） 的. 这个数据结构决定了整个框架的架构。还有被 `AVFoundation` 用来描述时间和媒体的底层数据结构，比如 `sample buffers ` 则是来自于 `Core Media Framework` 框架。

### 库的描述 Representation of Assets

[AVAsset](https://developer.apple.com/documentation/avfoundation/avasset) is the core class in the AV Foundation framework. It provides a format-independent abstraction of time-based audiovisual data, such as a movie file or a video stream. The primary relationships are shown in Figure 6-1. In many cases, you work with one of its subclasses: You use the composition subclasses when you create new assets (see [Editing](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/00_Introduction.html#//apple_ref/doc/uid/TP40010188-CH1-SW1)), and you use [AVURLAsset](https://developer.apple.com/documentation/avfoundation/avurlasset) to create a new asset instance from media at a given URL (including assets from the MPMedia framework or the Asset Library framework—see [Using Assets](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/01_UsingAssets.html#//apple_ref/doc/uid/TP40010188-CH7-SW1)).

`AVAsset` 是 `AVFoundation` 的核心类。他为基于时间的音视频数据 （`time-based audiovisual data`） （比如影片文件或者是视频流）提供了格式无关抽象描述。图 6-1 展示了他的主要关系。在通常情况下，你会使用他的一个具体的子类进行工作：如果要创建一个新的库, 那你需要合成器的子类 （`compostion`） （参考 [Editing](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/00_Introduction.html#//apple_ref/doc/uid/TP40010188-CH1-SW1))。如果你需要用一个 URL 来创建一个库实例，那要使用 `AVURLAsset`。（使用 `MPMedia` 框架或者 `Asset Library framework` 框架的库对象，参考 [Using Assets](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/01_UsingAssets.html#//apple_ref/doc/uid/TP40010188-CH7-SW1))。

![](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/avassetHierarchy_2x.png)

An asset contains a collection of tracks that are intended to be presented or processed together, each of a uniform media type, including (but not limited to) audio, video, text, closed captions, and subtitles. The asset object provides information about whole resource, such as its duration or title, as well as hints for presentation, such as its natural size. Assets may also have metadata, represented by instances of [AVMetadataItem](https://developer.apple.com/documentation/avfoundation/avmetadataitem).

每个库 （`asset`） 包含了很多的轨道 （`tracks`），他们被用作一起呈现或者处理，他们每个都是统一的媒体的类型，包括（但不限于）音频，视频，文本，隐藏式字幕 （`closed captions`） 和字幕。 库 （`asset`） 对象还提供整个资源的信息，诸如时长，标题，还有一些播放用的信息比如显示尺寸等。库 （`asset`） 还有一些元数据 （`metadata`），他们通过 [AVMetadataItem](https://developer.apple.com/documentation/avfoundation/avmetadataitem) 来描述。

A track is represented by an instance of [AVAssetTrack](https://developer.apple.com/documentation/avfoundation/avassettrack), as shown in Figure 6-2. In a typical simple case, one track represents the audio component and another represents the video component; in a complex composition, there may be multiple overlapping tracks of audio and video.

图 6-2 显示了，每个轨道 （`track`） 都是一个 `AVAssetTrack` 对象。在大多数时候，有一个视频轨道和一个音频轨道。但是在合成器中 （`compostion`）, 可能会有多个音频视频轨道的叠加。

![](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Art/avassetAndTracks_2x.png)

A track has a number of properties, such as its type (video or audio), visual and/or audible characteristics (as appropriate), metadata, and timeline (expressed in terms of its parent asset). A track also has an array of format descriptions. The array contains `CMFormatDescription` objects (see [CMFormatDescriptionRef](https://developer.apple.com/documentation/avfoundation/avassettrack)), each of which describes the format of media samples referenced by the track. A track that contains uniform media (for example, all encoded using to the same settings) will provide an array with a count of 1.

每个轨道有很多属性，类似类别 （`type`） (视频 `video` 或者音频 `audio`), 视听特性 （`characteristics`） （视情况而定），元数据，和时间线（依据他所在的 asset）。一个轨道也有一组格式的描述。他们是一个 `CMFormatDescription` 数组（参考 [CMFormatDescriptionRef](https://developer.apple.com/documentation/coremedia/cmformatdescription))，每个都是媒体采样 (`media sampels`) 格式。一些包含统一媒体的轨道（比如，所有已编码的都使用相同的设置）提供的这个数组只会包含一个内容。

A track may itself be divided into segments, represented by instances of [AVAssetTrackSegment](https://developer.apple.com/documentation/avfoundation/avassettracksegment). A segment is a time mapping from the source to the asset track timeline.

一个轨道可能会被切分为很多片段 （`segments`），他们都是 [AVAssetTrackSegment](https://developer.apple.com/documentation/avfoundation/avassettracksegment) 对象。每个片段都表示在这个轨道 （`asset track`）  的时间线上的一段映射。

### 对于时间的表示 Representations of Time

Time in AV Foundation is represented by primitive structures from the Core Media framework.

`AVFoundation` 框架中的时间是通过 `Core Media` 框架中的基础数据结构来表示的。

#### 使用 CMTime 表示时间长度 CMTime Represents a Length Time

[CMTime](https://developer.apple.com/documentation/coremedia/cmtime) is a C structure that represents time as a rational number, with a numerator (an `int64_t` value), and a denominator (an `int32_t` timescale). Conceptually, the timescale specifies the fraction of a second each unit in the numerator occupies. Thus if the timescale is 4, each unit represents a quarter of a second; if the timescale is 10, each unit represents a tenth of a second, and so on. You frequently use a timescale of 600, because this is a multiple of several commonly used frame rates: 24 fps for film, 30 fps for NTSC (used for TV in North America and Japan), and 25 fps for PAL (used for TV in Europe). Using a timescale of 600, you can exactly represent any number of frames in these systems

[CMTime](https://developer.apple.com/documentation/coremedia/cmtime) 是一个 C 的数据结构，他是一个表示时间的有理数。带有一个分子 （`numerator`） (一个 `int64_t` 的值)，以及一个分母 （`denominator`） (一个 `int32_t` 表示时间刻度). 从概念上来将，时间刻度 （`timescale`） 指的是将一秒划分为那么多的单位。所以如果时间刻度 （`timescale`） 是4，那么每个间隔就是 1/4 秒；如果时间刻度  （`timescale`） 是 10,那么每个间隔就是 1/10 秒以此类推。你经常使用的时间刻度 （`timescale`） 是 600,因为他是很多常见的帧率的倍数：比如电影是 24 帧每秒，NTSC 制式（在日本和北美电视中使用）30 帧每秒，PAL 制式 (欧洲电视）25 帧每秒。通过 600 这个时间刻度 （`timescale`），你可以在这些系统中精确的计算帧数。

In addition to a simple time value, a `CMTime` structure can represent nonnumeric values: +infinity, -infinity, and indefinite. It can also indicate whether the time been rounded at some point, and it maintains an epoch number.

除了简单的值, `CMTime`  结构还可以用于表示一些非数字的值，正负无穷大，以及不确定的值。It can also indicate whether the time been rounded at some point, and it maintains an epoch number.（不知道怎么翻？)

#### 使用 CMTime  Using CMTime

You create a time using [CMTimeMake](https://developer.apple.com/documentation/coremedia/1400785-cmtimemake) or one of the related functions such as [CMTimeMakeWithSeconds](https://developer.apple.com/documentation/coremedia/1400797-cmtimemakewithseconds)(which allows you to create a time using a float value and specify a preferred timescale). There are several functions for time-based arithmetic and for comparing times, as illustrated in the following example:

你可以使用 [CMTimeMake](https://developer.apple.com/documentation/coremedia/1400785-cmtimemake) 函数来创建时间, 也可以使用其他一些相关的函数来创建，比如 [CMTimeMakeWithSeconds](https://developer.apple.com/documentation/coremedia/1400797-cmtimemakewithseconds)，他可以让你用一个浮点数的值和一个指定的时间刻度值来创建时间。还有好多其他用于计算和进行时间比较的函数，下面的代码中示例：

	CMTime time1 = CMTimeMake(200, 2); // 200 half-seconds
	CMTime time2 = CMTimeMake(400, 4); // 400 quarter-seconds
	 
	// time1 and time2 both represent 100 seconds, but using different timescales.
	if (CMTimeCompare(time1, time2) == 0) {
	    NSLog(@"time1 and time2 are the same");
	}
	 
	Float64 float64Seconds = 200.0 / 3;
	CMTime time3 = CMTimeMakeWithSeconds(float64Seconds , 3); // 66.66... third-seconds
	time3 = CMTimeMultiply(time3, 3);
	// time3 now represents 200 seconds; next subtract time1 (100 seconds).
	time3 = CMTimeSubtract(time3, time1);
	CMTimeShow(time3);
	 
	if (CMTIME_COMPARE_INLINE(time2, ==, time3)) {
	    NSLog(@"time2 and time3 are the same");
	}

For a list of all the available functions, see [CMTime Reference](https://developer.apple.com/documentation/coremedia/cmtime-u58).

全部的函数请参考 [CMTime Reference](https://developer.apple.com/documentation/coremedia/cmtime-u58).

#### CMTime 的一些特殊值 Special Values of CMTime

Core Media provides constants for special values: `kCMTimeZero`, `kCMTimeInvalid`, `kCMTimePositiveInfinity`, and `kCMTimeNegativeInfinity`. There are many ways in which a `CMTime` structure can, for example, represent a time that is invalid. To test whether a CMTime is valid, or a nonnumeric value, you should use an appropriate macro, such as [CMTIME\_IS\_INVALID](https://developer.apple.com/documentation/coremedia/cmtime_is_invalid "CMTIME_IS_INVALID"),[CMTIME\_IS\_POSITIVE\_INFINITY](https://developer.apple.com/documentation/coremedia/cmtime_is_positive_infinity "CMTIME_IS_POSITIVE_INFINITY"),[CMTIME\_IS\_INDEFINITE](https://developer.apple.com/documentation/coremedia/cmtime_is_indefinite "CMTIME_IS_INDEFINITE").

`Core Media` 框架还提供了一些特殊的常量值，`kCMTimeZero`, `kCMTimeInvalid`, `kCMTimePositiveInfinity` 和 `kCMTimeNegativeInfinity`。这里还有很多种方法用来检测这个时间是否是有效的 （`invalid`）。要测试这个 `CMTime` 是有效的，或者是一个非数字的值，你可以使用下面这些宏： [CMTIME\_IS\_INVALID](https://developer.apple.com/documentation/coremedia/cmtime_is_invalid "CMTIME_IS_INVALID"), [CMTIME\_IS\_POSITIVE\_INFINITY](https://developer.apple.com/documentation/coremedia/cmtime_is_positive_infinity "CMTIME_IS_POSITIVE_INFINITY"), or [CMTIME\_IS\_INDEFINITE](https://developer.apple.com/documentation/coremedia/cmtime_is_indefinite "CMTIME_IS_INDEFINITE")。

	CMTime myTime = <#Get a CMTime#>;
	if (CMTIME_IS_INVALID(myTime)) {
	    // Perhaps treat this as an error; display a suitable alert to the user.
	}

You should not compare the value of an arbitrary CMTime structure with `kCMTimeInvalid`.

你不可以把任何一个 `CMTime` 值和 `kCMTimeInvalid` 进行比较。

#### 将 CMTime 转换为对象 Representing CMTime as an Object

If you need to use `CMTime` structures in annotations or Core Foundation containers, you can convert a `CMTime` structure to and from a `CFDictionary` opaque type (see [CFDictionaryRef](https://developer.apple.com/documentation/corefoundation/cfdictionaryref)) using the [CMTimeCopyAsDictionary](https://developer.apple.com/documentation/coremedia/1400845-cmtimecopyasdictionary) and [CMTimeMakeFromDictionary](https://developer.apple.com/documentation/coremedia/1400819-cmtimemakefromdictionary) functions, respectively. You can also get a string representation of a `CMTime` structure using the [CMTimeCopyDescription](https://developer.apple.com/documentation/coremedia/1400791-cmtimecopydescription) function.

如果你要将 `CMTime` 用于标注 （`annotations`） 或者是 `Core Foundation` 的容器类型 （`containers`），你可以将 `CMTime` 转换为一个 `CFDictionary` 对象 (参考 [CFDictionaryRef](https://developer.apple.com/documentation/corefoundation/cfdictionaryref))。分别使用 [CMTimeCopyAsDictionary](https://developer.apple.com/documentation/coremedia/1400845-cmtimecopyasdictionary) 和 [CMTimeMakeFromDictionary](https://developer.apple.com/documentation/coremedia/1400819-cmtimemakefromdictionary) 函数。你也可以通过 [CMTimeCopyDescription](https://developer.apple.com/documentation/coremedia/1400791-cmtimecopydescription) 将 `CMTime` 转换为字符串。

#### 时期 Epochs

The epoch number of a `CMTime` structure is usually set to 0, but you can use it to distinguish unrelated timelines. For example, the epoch could be incremented through each cycle using a presentation loop, to differentiate between time `N` in loop 0 and time `N` in loop 1.

`CMTime` 中的 `epoch` 值通常都是 0。但是你可以用他来区分不相干的时间线。比如，你可以在一个循环来周期性的递增这个值，以此来区分循环 0 中的时间 N, 和循环 1 中的时间 N。

#### 用 CMTimeRange 表示时间范围 CMTimeRange Represents a Time Range

[CMTimeRange](https://developer.apple.com/documentation/coremedia/cmtimerange) is a C structure that has a start time and duration, both expressed as `CMTime` structures. A time range does not include the time that is the start time plus the duration.

[CMTimeRange](https://developer.apple.com/documentation/coremedia/cmtimerange) 是一个 包含开始时间和持续时间的 C 结构，他们都是 `CMTime` 类型。这个时间访问并不包括 `开始时间 + 持续时间的那个时间点`。

You create a time range using [CMTimeRangeMake](https://developer.apple.com/documentation/coremedia/1462785-cmtimerangemake) or [CMTimeRangeFromTimeToTime](https://developer.apple.com/documentation/coremedia/1462817-cmtimerangefromtimetotime). There are constraints on the value of the `CMTime` epochs:

- `CMTimeRange` structures cannot span different epochs.
- The epoch in a `CMTime` structure that represents a timestamp may be nonzero, but you can only perform range operations (such as `CMTimeRangeGetUnion`) on ranges whose start fields have the same epoch.
- The epoch in a `CMTime` structure that represents a duration should always be 0, and the value must be nonnegative.

你可以使用 [CMTimeRangeMake](https://developer.apple.com/documentation/coremedia/1462785-cmtimerangemake) 或者 [CMTimeRangeFromTimeToTime](https://developer.apple.com/documentation/coremedia/1462817-cmtimerangefromtimetotime) 来创建这个时间范围，对于他的 `CMTime` 的时期 `epochs` 值，有一些限制：

- `CMTimeRange` 结构中不能跨域不同的时期 （`epochs`）;
- `CMTime` 中的时期 （`epoch`） 可能表示了一个非 0 的时间戳。但是这种时候你只能进行一些范围操作 （`range operations`） （比如 `CMTimeRangeGetUnion`)，或者对拥有相同时期 （`epoch`） 的开始字段 （`start fileld`） 进行操作；
- 在时长 （`duration`） 的字段的 `CMTime` 的时期 （`epoch`） 应该一直是0，而且他不可以是负值；

#### 使用时间范围 Working with Time Ranges

Core Media provides functions you can use to determine whether a time range contains a given time or other time range, to determine whether two time ranges are equal, and to calculate unions and intersections of time ranges, such as [CMTimeRangeContainsTime](https://developer.apple.com/documentation/coremedia/1462775-cmtimerangecontainstime), [CMTimeRangeEqual](https://developer.apple.com/documentation/coremedia/1462841-cmtimerangeequal), [CMTimeRangeContainsTimeRange](https://developer.apple.com/documentation/coremedia/1462830-cmtimerangecontainstimerange), and [CMTimeRangeGetUnion](https://developer.apple.com/documentation/coremedia/1462837-cmtimerangegetunion).

`Core Media` 框架还提供了一些函数用于检查一个时间是否在时间范围内，也可以用来检测两个时间范围是不是相等，以及计算两个时间范围的交集和合集。他们有 [CMTimeRangeContainsTime](https://developer.apple.com/documentation/coremedia/1462775-cmtimerangecontainstime), [CMTimeRangeEqual](https://developer.apple.com/documentation/coremedia/1462841-cmtimerangeequal), [CMTimeRangeContainsTimeRange](https://developer.apple.com/documentation/coremedia/1462830-cmtimerangecontainstimerange), [CMTimeRangeGetUnion](https://developer.apple.com/documentation/coremedia/1462837-cmtimerangegetunion)。

Given that a time range does not include the time that is the start time plus the duration, the following expression always evaluates to false:

因为时间范围并不包括最后的那个持续时间点，所以以下的表达式不会成立：

	CMTimeRangeContainsTime(range, CMTimeRangeGetEnd(range))

For a list of all the available functions, see CMTimeRange Reference.

完整的函数列表请参考 [CMTimeRange Reference](https://developer.apple.com/documentation/coremedia/cmtimerange-qts)

#### 时间范围的特殊值 Special Values of CMTimeRange

Core Media provides constants for a zero-length range and an invalid range, [kCMTimeRangeZero](https://developer.apple.com/documentation/coremedia/kcmtimerangezero) and [kCMTimeRangeInvalid](https://developer.apple.com/documentation/coremedia/kcmtimerangeinvalid), respectively. There are many ways, though in which a `CMTimeRange` structure can be invalid, or zero—or indefinite (if one of the CMTime structures is indefinite. If you need to test whether a CMTimeRange structure is valid, zero, or indefinite, you should use an appropriate macro: [CMTIMERANGE\_IS\_VALID](https://developer.apple.com/documentation/coremedia/cmtimerange_is_valid "CMTIMERANGE_IS_VALID"), [CMTIMERANGE\_IS\_INVALID](https://developer.apple.com/documentation/coremedia/cmtimerange_is_invalid "CMTIMERANGE_IS_INVALID"), [CMTIMERANGE\_IS\_EMPTY](https://developer.apple.com/documentation/coremedia/cmtimerange_is_empty "CMTIMERANGE_IS_EMPTY"), or [CMTIMERANGE\_IS\_EMPTY](https://developer.apple.com/documentation/coremedia/cmtimerange_is_empty "CMTIMERANGE_IS_EMPTY").

`Core Media` 分别提供了表示0长度的时间范围 [kCMTimeRangeZero](https://developer.apple.com/documentation/coremedia/kcmtimerangezero) 和无效的范围 [kCMTimeRangeInvalid](https://developer.apple.com/documentation/coremedia/kcmtimerangeinvalid)。有很多中方式，让 `CMTimeRange` 变的无效，或者0，或者无法确定的（如果其中一个 `CMTime` 是不确定的）。如果你要来确认这个 `CMTimeRange` 是不是有效的，0 或者是不确定的，你可以使用对应的宏 [CMTIMERANGE\_IS\_VALID](https://developer.apple.com/documentation/coremedia/cmtimerange_is_valid "CMTIMERANGE_IS_VALID"), [CMTIMERANGE\_IS\_INVALID](https://developer.apple.com/documentation/coremedia/cmtimerange_is_invalid "CMTIMERANGE_IS_INVALID"), [CMTIMERANGE\_IS\_EMPTY](https://developer.apple.com/documentation/coremedia/cmtimerange_is_empty "CMTIMERANGE_IS_EMPTY"), or [CMTIMERANGE\_IS\_EMPTY](https://developer.apple.com/documentation/coremedia/cmtimerange_is_empty "CMTIMERANGE_IS_EMPTY")。

	CMTimeRange myTimeRange = <#Get a CMTimeRange#>;
	if (CMTIMERANGE_IS_EMPTY(myTimeRange)) {
	    // The time range is zero.
	}

You should not compare the value of an arbitrary `CMTimeRange` structure with `kCMTimeRangeInvalid`.

你不应该把任何一个明确的 `CMTimeRange` 值和 `kCMTimeRangeInvalid` 进行比较。

#### 将 CMTimeRange 转换为对象 Representing a CMTimeRange Structure as an Object

If you need to use `CMTimeRange` structures in annotations or Core Foundation containers, you can convert a `CMTimeRange` structure to and from a `CFDictionary` opaque type (see [CFDictionaryRef](https://developer.apple.com/documentation/corefoundation/cfdictionaryref)) using [CMTimeRangeCopyAsDictionary](https://developer.apple.com/documentation/coremedia/1462781-cmtimerangecopyasdictionary) and [CMTimeRangeMakeFromDictionary](https://developer.apple.com/documentation/coremedia/1462777-cmtimerangemakefromdictionary), respectively. You can also get a string representation of a `CMTime` structure using the [CMTimeRangeCopyDescriptionfunction](https://developer.apple.com/documentation/coremedia/1462823-cmtimerangecopydescription).

如果你要在标注或者 `Core Foundation` 容器类型中使用 `CMTimeRange` 结构，你可以使用 [CMTimeRangeCopyAsDictionary](https://developer.apple.com/documentation/coremedia/1462781-cmtimerangecopyasdictionary) 和 [CMTimeRangeMakeFromDictionary](https://developer.apple.com/documentation/coremedia/1462777-cmtimerangemakefromdictionary) 将他转换为 `CFDictionary` 不透明类型（参考 [CFDictionaryRef](https://developer.apple.com/documentation/corefoundation/cfdictionaryref))。你也可以使用 [CMTimeRangeCopyDescriptionfunction](https://developer.apple.com/documentation/coremedia/1462823-cmtimerangecopydescription) 来将 `CMTime` 结构转化为一个字符串表示。

### 媒体的展现 Representations of Media

Video data and its associated metadata are represented in AV Foundation by opaque objects from the Core Media framework. Core Media represents video data using `CMSampleBuffer` (see [CMSampleBufferRef](https://developer.apple.com/documentation/coremedia/cmsamplebufferref)). `CMSampleBuffer` is a Core Foundation-style opaque type; an instance contains the sample buffer for a frame of video data as a Core Video pixel buffer (see [CVPixelBufferRef](https://developer.apple.com/documentation/corevideo/cvpixelbufferref)). You access the pixel buffer from a sample buffer using [CMSampleBufferGetImageBuffer](https://developer.apple.com/documentation/coremedia/1489236-cmsamplebuffergetimagebuffer):

`AVFoundation` 框架中的视频信息和他的元数据 （`metadata`） 是使用 `Core Media` 框架中的不透明对象来表示的。`Core Media` 使用 `CMSampleBuffer` (参考 [CMSampleBufferRef](https://developer.apple.com/documentation/coremedia/cmsamplebuffer)) 来表示视频信息。他是一个 `Core Foundation` 风格的不透明的类型，他所包含的帧的 `sample buffer`  是一种 `Core Video` 的像素缓冲（ `pixel buffer`） (参考 [CVPixelBufferRef](#))。你可以通过 [CMSampleBufferGetImageBuffer](https://developer.apple.com/documentation/coremedia/1489236-cmsamplebuffergetimagebuffer) 来获取 `sample buffer` 的像素缓冲 （`pixel buffer`）。

	CVPixelBufferRef pixelBuffer = CMSampleBufferGetImageBuffer(<#A CMSampleBuffer#>);
	

From the pixel buffer, you can access the actual video data. For an example, see [Converting CMSampleBuffer to a UIImage Object](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/06_MediaRepresentations.html#//apple_ref/doc/uid/TP40010188-CH2-SW4).

通过像素缓冲 （`pixel buffer`），你可以获取到真实的视频数据。比如你可以将 `CMSampleBuffer` 转换为图像 [Converting CMSampleBuffer to UIImage Object](https://developer.apple.com/library/content/documentation/AudioVideo/Conceptual/AVFoundationPG/Articles/06_MediaRepresentations.html#//apple_ref/doc/uid/TP40010188-CH2-SW4)。

In addition to the video data, you can retrieve a number of other aspects of the video frame:

- Timing information. You get accurate timestamps for both the original presentation time and the decode time using [CMSampleBufferGetPresentationTimeStamp](https://developer.apple.com/documentation/coremedia/1489252-cmsamplebuffergetpresentationtim) and [CMSampleBufferGetDecodeTimeStamp](https://developer.apple.com/documentation/coremedia/1489404-cmsamplebuffergetdecodetimestamp) respectively.
- Format information. The format information is encapsulated in a CMFormatDescription object (see [CMFormatDescriptionRef](https://developer.apple.com/documentation/coremedia/cmformatdescription)). From the format description, you can get for example the pixel type and video dimensions using `CMVideoFormatDescriptionGetCodecType` and [CMVideoFormatDescriptionGetDimensions](https://developer.apple.com/documentation/coremedia/1489287-cmvideoformatdescriptiongetdimen) respectively.
- Metadata. Metadata are stored in a dictionary as an attachment. You use [CMGetAttachment](https://developer.apple.com/documentation/coremedia/1470707-cmgetattachment) to retrieve the dictionary:

除了视频数据，你还可以获得视频帧的其他一些内容：

- 时间信息：你可以获取精确的时间戳，通过 [CMSampleBufferGetPresentationTimeStamp](https://developer.apple.com/documentation/coremedia/1489252-cmsamplebuffergetpresentationtim) 获取原始的显示时间，通过 [CMSampleBufferGetDecodeTimeStamp](https://developer.apple.com/documentation/coremedia/1489404-cmsamplebuffergetdecodetimestamp) 获取解码时间；
- 格式信息：格式信息是使用 `CMFormatDescription` 对象进行封装的 (参考 [CMFormatDescriptionRef](https://developer.apple.com/documentation/coremedia/cmformatdescription)). 通过这个对象，你可以使用 `CMVideoFormatDescriptionGetCodecType` 来获取像素类型（`pixel type`），也可以通过 [CMVideoFormatDescriptionGetDimensions](https://developer.apple.com/documentation/coremedia/1489287-cmvideoformatdescriptiongetdimen) 来获取视频尺寸。
- 元数据：元数据是存储在名为附件 （`attachment`） 的字典中的，你可以通过 [CMGetAttachment](https://developer.apple.com/documentation/coremedia/1470707-cmgetattachment) 来获取这个字典；

	CMSampleBufferRef sampleBuffer = <#Get a sample buffer#>;
	CFDictionaryRef metadataDictionary =
	    CMGetAttachment(sampleBuffer, CFSTR("MetadataDictionary", NULL);
	if (metadataDictionary) {
	    // Do something with the metadata.
	}
	

### 将 CMSampleBuffer 转换为图像对象 Converting CMSampleBuffer to a UIImage Object

The following code shows how you can convert a `CMSampleBuffer` to a `UIImage` object. You should consider your requirements carefully before using it. Performing the conversion is a comparatively expensive operation. It is appropriate to, for example, create a still image from a frame of video data taken every second or so. You should not use this as a means to manipulate every frame of video coming from a capture device in real time.

下面的代码演示了如何将 `CMSampleBuffer` 转换为 `UIImage` 对象。在使用这个代码的时候你要权衡一下。因为这个转换过程就是非常消耗性能的操作。举例来说，他比较适合为视频的每一秒来创建一个图像，但是不适合用在实时的视频采集中为每一帧都创建图像。

	// Create a UIImage from sample buffer data
	- (UIImage *) imageFromSampleBuffer:(CMSampleBufferRef) sampleBuffer
	{
	    // Get a CMSampleBuffer's Core Video image buffer for the media data
	    CVImageBufferRef imageBuffer = CMSampleBufferGetImageBuffer(sampleBuffer);
	    // Lock the base address of the pixel buffer
	    CVPixelBufferLockBaseAddress(imageBuffer, 0);
	 
	    // Get the number of bytes per row for the pixel buffer
	    void *baseAddress = CVPixelBufferGetBaseAddress(imageBuffer);
	 
	    // Get the number of bytes per row for the pixel buffer
	    size_t bytesPerRow = CVPixelBufferGetBytesPerRow(imageBuffer);
	    // Get the pixel buffer width and height
	    size_t width = CVPixelBufferGetWidth(imageBuffer);
	    size_t height = CVPixelBufferGetHeight(imageBuffer);
	 
	    // Create a device-dependent RGB color space
	    CGColorSpaceRef colorSpace = CGColorSpaceCreateDeviceRGB();
	 
	    // Create a bitmap graphics context with the sample buffer data
	    CGContextRef context = CGBitmapContextCreate(baseAddress, width, height, 8,
	      bytesPerRow, colorSpace, kCGBitmapByteOrder32Little | kCGImageAlphaPremultipliedFirst);
	    // Create a Quartz image from the pixel data in the bitmap graphics context
	    CGImageRef quartzImage = CGBitmapContextCreateImage(context);
	    // Unlock the pixel buffer
	    CVPixelBufferUnlockBaseAddress(imageBuffer,0);
	 
	    // Free up the context and color space
	    CGContextRelease(context);
	    CGColorSpaceRelease(colorSpace);
	 
	    // Create an image object from the Quartz image
	    UIImage *image = [UIImage imageWithCGImage:quartzImage];
	 
	    // Release the Quartz image
	    CGImageRelease(quartzImage);
	 
	    return (image);
	}

